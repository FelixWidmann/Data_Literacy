{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Loading Function\n",
    "def load_data():\n",
    "    data_file = \"../data/cleaned_processed_data.csv\"  # Adjust this path\n",
    "    merged_data_clean = pd.read_csv(data_file)\n",
    "\n",
    "    features = [\"CERQ_Sum\", \"ERQ_Sum\", \"MSPSS_Sum\", \"FSoZu_Sum\", \n",
    "                \"BISBAS_Total\", \"NEO_Sum\", \"STAI_Sum\", \"STAXI_Sum\", \n",
    "                \"CVLT_Sum\", \"TAP_Sum\", \"BloodPressure_Mean\", \"Age_Numeric\"]\n",
    "    \n",
    "    target = \"Relationship_Status\"\n",
    "    X = merged_data_clean[features]\n",
    "    y = merged_data_clean[target]\n",
    "\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Data loaded successfully with {X_train.shape[0]} training samples and {X_test.shape[0]} test samples.\")\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/samuel/Desktop/EKU%20Tu%CC%88bingen/data_literacy/project/repo/LEMON-Love-Predictor/code/mlruns/650246619203695642', creation_time=1734981523380, experiment_id='650246619203695642', last_update_time=1734981523380, lifecycle_stage='active', name='LEMON_Prediction_Relationship', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set MLflow Experiment\n",
    "mlflow.set_experiment(\"LEMON_Prediction_Relationship\")\n",
    "\n",
    "# Start the MLflow UI (Run this in the terminal if needed)\n",
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/cleaned_processed_data.csv...\n",
      "Data loaded successfully with 181 training samples and 46 test samples.\n",
      "Model: Random Forest, Accuracy: 0.5435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.24      0.28        17\n",
      "           1       0.62      0.72      0.67        29\n",
      "\n",
      "    accuracy                           0.54        46\n",
      "   macro avg       0.48      0.48      0.47        46\n",
      "weighted avg       0.51      0.54      0.52        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Load Data Function\n",
    "def load_data():\n",
    "    data_file = \"../data/cleaned_processed_data.csv\"  # Adjust path to your dataset\n",
    "    print(f\"Loading data from {data_file}...\")\n",
    "    merged_data_clean = pd.read_csv(data_file)\n",
    "    features = [\n",
    "        \"CERQ_Sum\", \"ERQ_Sum\", \"MSPSS_Sum\", \"FSoZu_Sum\", \n",
    "        \"BISBAS_Total\", \"NEO_Sum\", \"STAI_Sum\", \"STAXI_Sum\", \n",
    "        \"CVLT_Sum\", \"TAP_Sum\", \"BloodPressure_Mean\", \"Age_Numeric\"\n",
    "    ]\n",
    "    target = \"Relationship_Status\"\n",
    "    X = merged_data_clean[features]\n",
    "    y = merged_data_clean[target]\n",
    "    \n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Data loaded successfully with {len(X_train)} training samples and {len(X_test)} test samples.\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Define Model Training Function\n",
    "def train_model(model_type, max_iter, C, n_estimators, kernel):\n",
    "    # Load Data\n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "    # Initialize Model\n",
    "    if model_type == \"Logistic Regression\":\n",
    "        model = LogisticRegression(max_iter=max_iter, C=C, solver='lbfgs')\n",
    "    elif model_type == \"Random Forest\":\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=10, random_state=42)\n",
    "    elif model_type == \"SVM\":\n",
    "        model = SVC(C=C, kernel=kernel, max_iter=max_iter, probability=True)\n",
    "    \n",
    "    # Train the Model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    print(f\"Model: {model_type}, Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "# Create a sample input example from the training data\n",
    "    input_example = X_train.iloc[:1]\n",
    "\n",
    "# Log Model and Metrics in MLflow\n",
    "    with mlflow.start_run(run_name=f\"{model_type}_{kernel}_run\"):\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        mlflow.log_param(\"max_iter\", max_iter)\n",
    "        mlflow.log_param(\"C\", C)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"kernel\", kernel)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        \n",
    "        # Log the model with an input example\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"model\", input_example=input_example)\n",
    "    # # Log Model and Metrics in MLflow\n",
    "    # with mlflow.start_run(run_name=f\"{model_type}_{kernel}_run\"):\n",
    "    #     mlflow.log_param(\"model_type\", model_type)\n",
    "    #     mlflow.log_param(\"max_iter\", max_iter)\n",
    "    #     mlflow.log_param(\"C\", C)\n",
    "    #     mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    #     mlflow.log_param(\"kernel\", kernel)\n",
    "    #     mlflow.log_metric(\"accuracy\", acc)\n",
    "        \n",
    "    #     mlflow.sklearn.log_model(model, artifact_path=\"model\")\n",
    "\n",
    "# Train the Model Once\n",
    "train_model(\n",
    "    model_type=\"Random Forest\",  # Change to \"Random Forest\" or \"SVM\" as needed\n",
    "    max_iter=1000,\n",
    "    C=1.0,\n",
    "    n_estimators=100,  # Only used for Random Forest\n",
    "    kernel=\"linear\"    # Only used for SVM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hyperparameter Sweep Config\n",
    "sweep_config = {\n",
    "    \"model_type\": [ \"Random Forest\", \"SVM\"],\n",
    "    \"max_iter\": list(range(100, 1001, 100)),\n",
    "    \"C\": np.linspace(0.1, 10, 10).tolist(),\n",
    "    \"n_estimators\": list(range(50, 301, 50)),\n",
    "    \"kernel\": [\"linear\", \"rbf\"]\n",
    "}\n",
    "\n",
    "# Create All Combinations\n",
    "sweep_params = list(product(\n",
    "    sweep_config[\"model_type\"], \n",
    "    sweep_config[\"max_iter\"], \n",
    "    sweep_config[\"C\"], \n",
    "    sweep_config[\"n_estimators\"], \n",
    "    sweep_config[\"kernel\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Model Training for All Combinations\n",
    "for params in sweep_params:\n",
    "    model_type, max_iter, C, n_estimators, kernel = params\n",
    "\n",
    "    # Skip Irrelevant Combinations\n",
    "    if model_type == \"Logistic Regression\" and kernel != \"linear\":\n",
    "        continue\n",
    "    \n",
    "    train_model(model_type, max_iter, C, n_estimators, kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
